#!/bin/ksh
#
#@ output = /meso/save/wx22ec/NEMS/exp/nmm
#@ error = /meso/save/wx22ec/NEMS/exp/gfs
#@ job_type = parallel
#@ tasks_per_node = 32
#@ node = 1
#@ node_usage=not_shared
#@ resources=ConsumableCPUs(1)ConsumableMemory(500MB)
#@ class = debug
#@ wall_clock_limit = 00:10:00
#@ preferences = Feature == "dev"
#@ network.MPI = csss,shared,us
#@ bulkxfer=yes
#@ account_no=NAM-T2O
#@ queue
#
#
set -x
#
### For MPI
#
export BIND_TASKS=no
export MP_EAGER_LIMIT=65536
export MP_SHARED_MEMORY=yes
export MP_SINGLE_THREAD=yes
export MP_LABELIO=yes
export MP_STDOUTMODE=ordered
export MEMORY_AFFINITY=mcm
export MP_COREFILE_FORMAT=core.txt
export TARGET_CPU_RANGE="-1"
export XLSMPOPTS="parthds=1:stack=128000000"
export AIXTHREAD_SCOPE=S

RUNDIR=/ptmp/${USER}/test
DATADIR=/stmp/wx20py/nmmb_init
SRCDIR=/meso/save/wx22ec/NEMS

mkdir -p $RUNDIR
cd $RUNDIR

rm -f $RUNDIR/*

cp $DATADIR/test_input_umo_regional.d01 main_input_filename
cp ../exp/configure_files/configfile_global_new configure_file
 
cp /meso/save/wx22ec/test/tr* .

cp /nwprod/fix/nam_micro_lookup.dat ETAMPNEW_DATA
cp /meso/save/wx22ec/test/RRT* .
cp /meso/save/wx22ec/test/*.TBL .

echo "Model started:  " `date`

poe hpmcount -o nmm.0.test /u/wx15ja/bin/hybrid_launch /meso/save/wx22ec/NEMS/exe/NMM_NEMS.x
echo "Model ended:    " `date`

exit

